{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:51:21.769792Z",
     "start_time": "2019-02-26T09:51:15.598069Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the base table\n",
    "\n",
    "Before diving into model building, it is important to understand the data you are working with. In this exercise, you will learn how to obtain the population size, number of targets and target incidence from a given basetable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:01:35.245255Z",
     "start_time": "2019-02-26T10:01:35.061721Z"
    }
   },
   "outputs": [],
   "source": [
    "basetable = pd.read_csv('40Data1.csv', index_col = 0, parse_dates = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:01:35.361040Z",
     "start_time": "2019-02-26T10:01:35.353029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "4990\n",
      "0.0499\n"
     ]
    }
   ],
   "source": [
    "# Assign the number of rows in the basetable to the variable 'population_size'.\n",
    "population_size  = len(basetable)\n",
    "\n",
    "# Print the population size.\n",
    "print(population_size)\n",
    "\n",
    "# Assign the number of targets to the variable 'targets_count'.\n",
    "targets_count = sum(basetable[\"target\"])\n",
    "\n",
    "# Print the number of targets.\n",
    "print(targets_count)\n",
    "\n",
    "# Print the incidence, i.e. the number of targets divided by the population size.\n",
    "print(targets_count/population_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the predictive variables\n",
    "\n",
    "It is always useful to get a better understanding of the population. Therefore, one can have a closer look at the predictive variables. Recall that you can select a column in a pandas dataframe by indexing as follows:\n",
    "\n",
    "    basetable[\"variable\"]\n",
    "\n",
    "To count the number of occurrences of a certain value in a column, you can use the sum method:\n",
    "\n",
    "    sum(basetable[\"variable\"]==value)\n",
    "\n",
    "In this exercise you will find out whether there are more males than females in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:01:39.073027Z",
     "start_time": "2019-02-26T10:01:39.035160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50624\n",
      "49376\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of females.\n",
    "print(sum(basetable[\"gender\"]==\"F\"))\n",
    "\n",
    "# Count and print the number of males.\n",
    "print(sum(basetable[\"gender\"]==\"M\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a logistic regression model\n",
    "\n",
    "You can build a logistic regression model using the module linear_model from sklearn. First, you create a logistic regression model using the LogisticRegression() method:\n",
    "\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "\n",
    "Next, you need to feed data to the logistic regression model, so that it can be fit. X contains the predictive variables, whereas y has the target.\n",
    "\n",
    "    X = basetable[[\"predictor_1\",\"predictor_2\",\"predictor_3\"]]`\n",
    "    y = basetable[[\"target\"]]\n",
    "    logreg.fit(X,y)\n",
    "\n",
    "In this exercise you will build your first predictive model using three predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:04:29.761736Z",
     "start_time": "2019-02-26T10:04:29.689900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>income_high</th>\n",
       "      <th>income_low</th>\n",
       "      <th>country_USA</th>\n",
       "      <th>country_India</th>\n",
       "      <th>country_UK</th>\n",
       "      <th>age</th>\n",
       "      <th>time_since_last_gift</th>\n",
       "      <th>time_since_first_gift</th>\n",
       "      <th>max_gift</th>\n",
       "      <th>min_gift</th>\n",
       "      <th>mean_gift</th>\n",
       "      <th>number_gift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>530</td>\n",
       "      <td>2265</td>\n",
       "      <td>166.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>1806</td>\n",
       "      <td>125.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>96.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "      <td>2274</td>\n",
       "      <td>117.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>104.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  gender_F  income_high  income_low  country_USA  country_India  \\\n",
       "0       0         1            0           1            0              1   \n",
       "1       0         1            0           0            0              1   \n",
       "2       0         1            0           0            0              1   \n",
       "3       0         1            0           1            1              0   \n",
       "4       0         1            1           0            1              0   \n",
       "\n",
       "   country_UK  age  time_since_last_gift  time_since_first_gift  max_gift  \\\n",
       "0           0   65                   530                   2265     166.0   \n",
       "1           0   71                   715                    715      90.0   \n",
       "2           0   28                   150                   1806     125.0   \n",
       "3           0   52                   725                   2274     117.0   \n",
       "4           0   82                   805                    805      80.0   \n",
       "\n",
       "   min_gift  mean_gift  number_gift  \n",
       "0      87.0     116.00            7  \n",
       "1      90.0      90.00            1  \n",
       "2      74.0      96.00            9  \n",
       "3      97.0     104.25            4  \n",
       "4      80.0      80.00            1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable = pd.read_csv('basetable_ex2_4.csv', parse_dates = True)\n",
    "basetable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:04:30.113860Z",
     "start_time": "2019-02-26T10:04:30.012132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import linear_model from sklearn.\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create a dataframe X that only contains the candidate predictors age, gender_F and time_since_last_gift.\n",
    "X = basetable[[\"age\",\"gender_F\",\"time_since_last_gift\"]]\n",
    "\n",
    "# Create a dataframe y that contains the target.\n",
    "y = basetable[[\"target\"]]\n",
    "\n",
    "# Create a logistic regression model logreg and fit it to the data.\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the coefficients and intercept\n",
    "\n",
    "Once the logistic regression model is ready, it can be interesting to have a look at the coefficients to check whether the model makes sense.\n",
    "\n",
    "Given a fitted logistic regression model logreg, you can retrieve the coefficients using the attribute coef_. The order in which the coefficients appear, is the same as the order in which the variables were fed to the model. The intercept can be retrieved using the attribute intercept_.\n",
    "\n",
    "The logistic regression model that you built in the previous exercises has been added and fitted for you in logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:04:54.593495Z",
     "start_time": "2019-02-26T10:04:54.496724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\t0.007178355659086629\n",
      "gender_F\t0.11430414536348246\n",
      "time_since_last_gift\t-0.00130875011331457\n",
      "[-2.54149728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Construct a logistic regression model that predicts the target using age, gender_F and time_since_last gift\n",
    "predictors = [\"age\",\"gender_F\",\"time_since_last_gift\"]\n",
    "X = basetable[predictors]\n",
    "y = basetable[[\"target\"]]\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Assign the coefficients to a list coef\n",
    "coef = logreg.coef_\n",
    "for p,c in zip(predictors,list(coef[0])):\n",
    "    print(p + '\\t' + str(c))\n",
    "\n",
    "# Assign the intercept to the variable intercept\n",
    "intercept = logreg.intercept_\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions\n",
    "\n",
    "Once your model is ready, you can use it to make predictions for a campaign. It is important to always use the latest information to make predictions.\n",
    "\n",
    "In this exercise you will, given a fitted logistic regression model, learn how to make predictions for a new, updated basetable.\n",
    "\n",
    "The logistic regression model that you built in the previous exercises has been added and fitted for you in logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:06:00.491916Z",
     "start_time": "2019-02-26T10:06:00.485919Z"
    }
   },
   "outputs": [],
   "source": [
    "current_data = basetable.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:06:00.904922Z",
     "start_time": "2019-02-26T10:06:00.775269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93427169 0.06572831]\n",
      " [0.9454883  0.0545117 ]\n",
      " [0.9185279  0.0814721 ]\n",
      " [0.95269877 0.04730123]\n",
      " [0.94745512 0.05254488]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression model\n",
    "from sklearn import linear_model\n",
    "X = basetable[[\"age\",\"gender_F\",\"time_since_last_gift\"]]\n",
    "y = basetable[[\"target\"]]\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "# Create a dataframe new_data from current_data that has only the relevant predictors \n",
    "new_data = current_data[[\"age\",\"gender_F\",\"time_since_last_gift\"]]\n",
    "\n",
    "# Make a prediction for each observation in new_data and assign it to predictions\n",
    "predictions = logreg.predict_proba(new_data)\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Donor that is most likely to donate\n",
    "\n",
    "The predictions that result from the predictive model reflect how likely it is that someone is a target. For instance, assume that you constructed a model to predict whether a donor will donate more than 50 Euro for a certain campaign. If the prediction for a certain donor is 0.82, it means that there is an 82% chance that he will donate more than 50 Euro.\n",
    "\n",
    "In this exercise you will find the donor that is most likely to donate more than 50 Euro.\n",
    "\n",
    "Recall that you can sort a pandas dataframe df according to a certain column c using\n",
    "\n",
    "    df_sorted = df.sort([\"c\"])\n",
    "\n",
    "and that you can select the first and last row of a pandas dataframe using\n",
    "\n",
    "    first_row = df.head(1)\n",
    "    last_row = df.tail(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:06:34.514901Z",
     "start_time": "2019-02-26T10:06:34.497919Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type list)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-cdf9120808e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Sort the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"probability\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Select the last row of the sorted predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions_sorted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type list)"
     ]
    }
   ],
   "source": [
    "# Sort the predictions\n",
    "predictions_sorted = predictions.sort([\"probability\"])\n",
    "\n",
    "# Select the last row of the sorted predictions\n",
    "print(predictions_sorted.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward stepwise variable selection for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating AUC\n",
    "\n",
    "The AUC value assesses how well a model can order observations from low probability to be target to high probability to be target. In Python, the roc_auc_score function can be used to calculate the AUC of the model. It takes the true values of the target and the predictions as arguments.\n",
    "\n",
    "You will make predictions again, before calculating its roc_auc_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T10:08:09.888215Z",
     "start_time": "2019-02-26T10:08:09.872252Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-bf08cec92416>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Calculate the AUC value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mauc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = logreg.predict_proba(X)\n",
    "predictions_target = predictions[:,1]\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc = roc_auc_score(y, predictions_target)\n",
    "print(round(auc,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
